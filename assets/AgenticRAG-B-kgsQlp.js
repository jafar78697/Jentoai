import{r,j as e}from"./index-CfXYCDxE.js";import"./vendor-react-B--z-fyW.js";const i=({setPage:t})=>(r.useEffect(()=>{window.scrollTo(0,0)},[]),e.jsx("section",{className:"py-32 bg-white min-h-screen",children:e.jsxs("div",{className:"max-w-4xl mx-auto px-6",children:[e.jsxs("div",{className:"mb-16 reveal",children:[e.jsx("button",{onClick:()=>t("resources"),className:"text-[10px] font-black text-blue-600 uppercase tracking-widest mb-6 hover:underline",children:"← Back to Resources"}),e.jsx("div",{className:"inline-flex items-center gap-2 px-4 py-2 bg-cyan-50 text-cyan-700 rounded-full text-[10px] font-black uppercase tracking-widest mb-6",children:"Architecture Guide"}),e.jsx("h1",{className:"text-4xl md:text-5xl font-black text-slate-900 leading-tight mb-6",children:"Beyond Vector DBs: Implementing Agentic RAG"}),e.jsx("p",{className:"text-xl text-slate-500 font-medium leading-relaxed",children:"Standard RAG retrieves documents. Agentic RAG reasons about them. Learn the architecture that makes AI answers actually accurate."})]}),e.jsxs("div",{className:"prose prose-lg prose-slate max-w-none reveal",children:[e.jsx("h2",{className:"text-2xl font-black text-slate-900 mt-12 mb-4",children:"The Problem with Standard RAG"}),e.jsx("p",{children:"Traditional Retrieval-Augmented Generation (RAG) works like this: you ask a question, the system finds similar documents in a vector database, and an LLM generates an answer based on those documents."}),e.jsxs("p",{children:["The problem? ",e.jsx("strong",{children:"Similarity ≠ Relevance."})," Vector search finds documents that look similar, not documents that actually answer your question. This leads to hallucinations, incomplete answers, and frustrated users."]}),e.jsxs("div",{className:"p-6 bg-red-50 border border-red-100 rounded-2xl my-8 not-prose",children:[e.jsx("h4",{className:"text-sm font-black text-red-600 uppercase tracking-widest mb-2",children:"The Accuracy Gap"}),e.jsx("p",{className:"text-red-800 text-sm font-medium",children:"Standard RAG pipelines often struggle to surpass 75-85% accuracy on complex queries because they lack the ability to self-correct or validate retrieved information."})]}),e.jsx("h2",{className:"text-2xl font-black text-slate-900 mt-12 mb-4",children:"The Agentic RAG Architecture"}),e.jsx("p",{children:'Agentic RAG introduces a reasoning layer between retrieval and generation. Instead of blindly trusting retrieved documents, an "Evaluator Agent" assesses their quality and can request additional searches.'}),e.jsx("div",{className:"my-12 not-prose",children:e.jsxs("div",{className:"p-8 bg-slate-900 rounded-3xl",children:[e.jsxs("svg",{viewBox:"0 0 600 200",className:"w-full h-auto","aria-label":"Agentic RAG Architecture Diagram showing Query flowing to Meta-Agent, then to Retriever and Evaluator in a loop, finally to Generator for Answer",children:[e.jsx("rect",{x:"20",y:"80",width:"80",height:"40",rx:"8",fill:"#3b82f6"}),e.jsx("text",{x:"60",y:"105",textAnchor:"middle",fill:"white",fontSize:"12",fontWeight:"bold",children:"Query"}),e.jsx("rect",{x:"140",y:"80",width:"100",height:"40",rx:"8",fill:"#6366f1"}),e.jsx("text",{x:"190",y:"105",textAnchor:"middle",fill:"white",fontSize:"12",fontWeight:"bold",children:"Meta-Agent"}),e.jsx("rect",{x:"280",y:"40",width:"80",height:"40",rx:"8",fill:"#06b6d4"}),e.jsx("text",{x:"320",y:"65",textAnchor:"middle",fill:"white",fontSize:"11",fontWeight:"bold",children:"Retriever"}),e.jsx("rect",{x:"280",y:"120",width:"80",height:"40",rx:"8",fill:"#f59e0b"}),e.jsx("text",{x:"320",y:"145",textAnchor:"middle",fill:"white",fontSize:"11",fontWeight:"bold",children:"Evaluator"}),e.jsx("rect",{x:"400",y:"80",width:"80",height:"40",rx:"8",fill:"#10b981"}),e.jsx("text",{x:"440",y:"105",textAnchor:"middle",fill:"white",fontSize:"11",fontWeight:"bold",children:"Generator"}),e.jsx("rect",{x:"520",y:"80",width:"60",height:"40",rx:"8",fill:"#3b82f6"}),e.jsx("text",{x:"550",y:"105",textAnchor:"middle",fill:"white",fontSize:"12",fontWeight:"bold",children:"Answer"}),e.jsx("path",{d:"M100 100 L140 100",stroke:"#64748b",strokeWidth:"2",markerEnd:"url(#arrowhead)"}),e.jsx("path",{d:"M240 100 L280 60",stroke:"#64748b",strokeWidth:"2",markerEnd:"url(#arrowhead)"}),e.jsx("path",{d:"M240 100 L280 140",stroke:"#64748b",strokeWidth:"2",markerEnd:"url(#arrowhead)"}),e.jsx("path",{d:"M360 60 L360 120",stroke:"#64748b",strokeWidth:"2",strokeDasharray:"5,5"}),e.jsx("path",{d:"M360 140 L280 60",stroke:"#f59e0b",strokeWidth:"2",strokeDasharray:"5,5"}),e.jsx("path",{d:"M360 100 L400 100",stroke:"#64748b",strokeWidth:"2",markerEnd:"url(#arrowhead)"}),e.jsx("path",{d:"M480 100 L520 100",stroke:"#64748b",strokeWidth:"2",markerEnd:"url(#arrowhead)"}),e.jsx("text",{x:"390",y:"90",fill:"#f59e0b",fontSize:"9",fontWeight:"bold",children:"LOOP"}),e.jsx("defs",{children:e.jsx("marker",{id:"arrowhead",markerWidth:"10",markerHeight:"7",refX:"9",refY:"3.5",orient:"auto",children:e.jsx("polygon",{points:"0 0, 10 3.5, 0 7",fill:"#64748b"})})})]}),e.jsx("p",{className:"text-center text-slate-400 text-[10px] font-bold uppercase tracking-widest mt-4",children:"Agentic RAG: Perception → Retrieval → Evaluation → Generation Loop"})]})}),e.jsx("h3",{className:"text-xl font-bold text-slate-900 mt-8 mb-4",children:"The Three Agents"}),e.jsxs("ol",{className:"list-decimal pl-5 space-y-4",children:[e.jsxs("li",{children:[e.jsx("strong",{children:"Meta-Agent (Orchestrator):"})," Receives the query, decides the retrieval strategy, and coordinates the other agents."]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Retriever Agent:"})," Searches the vector database, can reformulate queries if initial results are poor."]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Evaluator Agent:"})," Assesses retrieved documents for relevance, accuracy, and completeness. Can trigger re-retrieval."]})]}),e.jsx("h2",{className:"text-2xl font-black text-slate-900 mt-12 mb-4",children:"Why It Matters"}),e.jsxs("p",{children:["With Agentic RAG, your AI doesn't just find information—it ",e.jsx("em",{children:"validates"})," it. The iterative loop allows the system to self-correct, dramatically improving answer quality for complex, multi-faceted queries."]})]}),e.jsxs("div",{className:"mt-16 text-center reveal",children:[e.jsx("p",{className:"text-slate-500 mb-6",children:"Need help implementing Agentic RAG for your knowledge base?"}),e.jsx("button",{onClick:()=>t("book-call"),className:"px-8 py-4 bg-blue-600 text-white rounded-xl font-black uppercase tracking-widest text-xs hover:bg-blue-700 transition-colors shadow-lg shadow-blue-500/30",children:"Talk to Our Architects"})]})]})}));export{i as default};
